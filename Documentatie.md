Functionalitate
Proiectul urmareste creearea unui asistent pentru invatarea domeniului juridic, care raspunde la intrebari in limbaj natural. Ideea e simpla: pui o intrebare si primesti un raspuns concis, orientat pe regula care se aplica. Daca nu exista suficient suport in date, asistentul spune direct ca nu poate raspunde. Scopul este sa ajute rapid la invatare si recapitulare, fara sa inventeze lucruri.
Din punctul de vedere al utilizatorului, fluxul e previzibil: intrebare => raspuns sau abtinere. Abtinerea a fost adaugata pentru evitarea confuziilor si a raspunsurilor lungi care nu ajuta. Asistentul nu intra in discutii elaborate si nu cere clarificari, tinand lucrurile scurte si la obiect, strict in limita a ceea ce are in date.
Articole de interes
GRAF (ACL 2025): Graph Retrieval Augmented by Facts pentru MCQA juridic in romana

GRAF (ACL 2025) prezinta, pentru domeniul juridic romanesc, trei resurse deschise si un model nou pentru MCQA: JuRO (10.836 intrebari cu variante), CROL (corpus organizat de legi cu versiuni in timp, 93 documente, 763 intervale) si Law-RoG (primul knowledge graph legal in romana). Autorii motiveaza nevoia unor date publice si standardizate pentru QA juridic in limbi putin reprezentate si livreaza atat colectiile, cat si codul experimental, pozitionand lucrarea ca reper pe directia Information Retrieval si reprezentari structurate pentru dreptul romanesc. 
Metoda propusa, GRAF (Graph Retrieval Augmented by Facts), este un pipeline claim-aware peste Knowledge Graph: pentru fiecare pereche (intrebare, optiune) se extrage cu un LLM un claim graph (entitati/relatii), se mosteneste un sub-Knowledge Graph din Law-RoG printr-un BM25 cu tokenizare si selectie pe vecinatate limitata, apoi se encodeaza nodurile si relatiile si se aplica un GAT adaptat, scorul final pe optiune rezulta prin self-attention intre (Q||C) si informatia agregata din sub-Knowledge Graph. In paralel, lucrarea include, ca baseline, un LLM cu RAG clasic: BM25 pe CROL, articole “chunk-uite” la aprox. 50 de cuvinte, top-10 pasaje concatenate in prompt, dar fara un reranker antrenat separat. Aceasta separa clar contributia KG/claim-aware de un RAG text-only minimal.
Empiric, GRAF depaseste baseline-urile pe toate tipurile de examene (intrare, barou, promovare), iar ablatia arata ca eliminarea claim graph sau a Knowledge Graph scade semnificativ performanta (ex.: 55.61% vs 53.14%/53.61% pe promovare). Autorii noteaza explicit limitele: cel mai bun scor mediu se situeaza in jur de ~56–60%, insuficient pentru uz operational fara validare umana. Pentru un proiect axat pe QA cu RAG, textul ofera atat un reper de date/benchmark, cat si o comparatie relevanta: RAG-ul lor nu foloseste reranker antrenat, ceea ce lasa spatiu clar pentru imbunatatiri printr-un RAG + reranker (si, in cazul nostru, o politica de abstinenta), chiar daca taskul nostru este QA liber, nu MCQA.
AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models
AGIEval este un benchmark „uman-centric” construit din examene standardizate reale (admitere la facultate, LSAT, barou/qualificare avocat, concursuri de matematica, examene pentru functia publica), conceput pentru a evalua capacitatile generale ale modelelor fundatie in contexte apropiate de sarcinile pe care le rezolva oamenii. Itemii sunt obiectivi (grila sau completare), iar evaluarile sunt rulate in setari zero-shot, few-shot si cu Chain-of-Thought, astfel incat sa se observe atat adaptarea fara exemple, cat si sensibilitatea la „gandire explicata”. Benchmarkul acopera atat engleza, cat si chineza, ceea ce il face util pentru comparatii cross-lingvistice. 
Rezultatele arata ca GPT-4 depaseste in medie performanta umana pe anumite examene (de ex. SAT, LSAT, competitii de matematica) si atinge scoruri foarte ridicate pe componente specifice (ex. ~95% pe SAT Math, ~92.5% pe Gaokao English), dar ramane vulnerabil la sarcini cu rationament complex, calcule elaborate sau cunostinte de domeniu foarte specifice (ex. drept, chimie, fizica). Analizele calitative evidentiaza punctele tari (intelegere buna a textului, deductii simple) si punctele slabe (lanturi de rationament multi-hop, deductie strict logica, erori de cunostinte de nisa), sugerand ca introducerea de cunostinte externe sau proceduri mai robuste de verificare ar putea imbunatati fiabilitatea. 
Pentru un proiect axat pe evaluarea LLM-urilor pe examene juridice, AGIEval conteaza mai ales ca principiu de design si reper metodologic: foloseste probe uman-centrice, oficiale, defineste masuri clare (acuratete/EM/F1), separa limpede limbile si subiectele, si testeaza setari moderne de prompting. Concluzia utila este ca modelele pot parea „foarte bune” pe examene generale, dar pot cadea la rationament juridic fin sau la probleme ce cer ancorare riguroasa in reguli, un argument puternic pentru folosirea unui RAG cu abstinenta atunci cand suportul din corpus nu este suficient.
Arhitectura

Proiectul urmeaza un design de tip retrieval-augmented generation (RAG) adaptat pentru dreptul romanesc si pentru explicatii graduale, in stil tutor. Baza de cunostinte este organizata ca „documente” uniforme, fiecare reprezentand un articol de lege citabil, cu identificator stabil (domeniu, lege, articol, an), continut lizibil (titlul legii, antetul articolului, textul) si metadate minimale pentru citare, filtrare si versiuni. Sunt pregatite doua „vederi” complementare de cautare: una lexicala pentru potriviri exacte si numere de articol si una semantica, in care fiecare document este proiectat ca vector astfel incat pasajele conceptual asemanatoare sa fie aproape. Ambele vederi referentiaza aceleasi documente canonice printr-o mapa simpla id => document, pentru a pastra citarea auditabila.
La primirea unei intrebari, textul este normalizat si sunt cautate rapid semnale juridice evidente (de ex. „art. 969”, aliasuri de legi). Recuperarea ruleaza in mod hibrid: indexul lexical intoarce candidatul cu potrivirea exacta, iar indexul semantic intoarce cele mai apropiate ca sens. Deoarece scorurile brute nu sunt comparabile, listele sunt combinate prin reciprocal rank fusion (RRF), apoi se aplica un pas scurt de diversitate (tip MMR) si o regula „one-per-article” pentru a evita duplicatele. Primele rezultate (in general 6-8 fragmente) constituie setul de context.
Fiecare fragment de context este afisat ca bloc scurt si auditabil: un header de citare (lege - articol - an) si un fragment. Modelul primeste aceste blocuri cu instructiuni stricte: sa selecteze silentios ce este relevant si sa raspunda in trei pasi: (1) Hint (orientare fara a „da” exact articolul), (2) Explicatie (parafraza clara a regulii aplicabile) si (3) Raspuns final cu citari exacte luate exclusiv din contextul furnizat. In lipsa unor dovezi suficiente, asistentul trebuie sa indice explicit ca nu are datele necesare pentru a raspunde.
Setul de date
Setul de date principal: CROL. In proiect se va utiliza CROL (Corpus for Romanian Law, un corpus organizat de drept romanesc extras din surse oficiale. CROL include acte normative cu versiuni pe intervale temporale si este structurat la nivel de articole, ceea ce il face adecvat pentru interogari ancorate in textul legal si pentru citare consecventa. In acest aranjament, CROL furnizeaza continutul normativ pe baza caruia asistentul formuleaza raspunsurile. Acest set de date asigura un limbaj formal si coerent, organizat pe acte si articole, cu posibilitatea de filtrare pe ramuri si, acolo unde este relevant, pe perioade. Structura clara sprijina un flux reproductibil pentru evaluare academica si reduce riscul de erori asociate surselor neoficiale. CROL ramane sursa normativa de referinta pentru validarea raspunsurilor.
Un posibil set de date complementar: examenele de licenta de la facultatile de drept din Romania. Itemii existenti in format MCQA din examenele de licenta vor fi transformati in afirmatii declarative (de tipul „Enunt + varianta corecta” => o singura propozitie afirmativa) si vor fi adaugati efectiv in baza de cunostinte RAG, alaturi de articolele din CROL. Afirmatiile vor fi normalizate si organizate pe ani/facultati, astfel incat sa existe context didactic si posibilitate de filtrare la nevoie. Scopul lor este sa creasca acoperirea pe formulari uzuale din examen si sa ofere puncte de ancorare pentru intrebarile puse pe stilul unui examen, fara sa fie necesara antrenare suplimentara.

